{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPhsOVtOO6cE55csckMN3I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IanChoi2464/Machine-Learning-Colab/blob/main/7-2%20Deep%20Neural%20Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "인공 신경망에 층을 여러 개 추가하여 패션 MNIST 데이터셋을 분류하면서 케라스로 심층 신경망을 만드는 방법을 자세히 배운다.\n",
        "# Keyword\n",
        "**심층 신경망**: deep neural network, DNN, 2개 이상의 층을 포함한 신경망, 종종 다층 인공 신경망, 심층 신경망, 딥러닝을 같은 의미로 사용\\\n",
        "**렐루 함수**: ReLU, 이미지 분류 모델의 은닉층에 많이 사용하는 활성화 함수, 시그모이드 함수는 층이 많을수록 활성화 함수의 양쪽 끝에서 변화가 작기 때문에 학습이 어려움, 렐루 함수는 이런 문제가 없으며 계산도 간단\\\n",
        "**옵티마이저**: optimizer, 신경망의 가중치와 절편을 학습하기 위한 알고리즘 또는 방법, 케라스에는 다양한 경사 하강법 알고리즘이 구현되어 있음, 대표적으로 SGD, 네스테로프 모멘텀, RMSprop, Adam 등이 있음\\\n",
        "# Function\n",
        "### **Tensorflow**\n",
        "**add()**: 케라스 모델에 층을 추가하는 메서드\\\n",
        "케라스 모델의 add() 메서드는 keras.layers 패키지 아래에 있는 층의 객체를 입력받아 신경망 모델에 추가, add() 메서드를 호출하여 전달한 순서대로 층이 차례대로 늘어남\\\n",
        "**summary()**: 케라스 모델의 정보를 출력하는 메서드\\\n",
        "모델에 추가된 층의 종류와 순서, 모델 파라미터 개수를 출력, 층을 만들 때 name 매개변수로 이름을 지정할 수도 있음\\\n",
        "**SGD**: 기본 경사 하강법 옵티마이저 클래스\\\n",
        "learning_rate 매개변수로 학습률을 지정하며 기본값은 0.01\\\n",
        "momentum 매개변수에 0 이상의 값을 지정하면 모멘텀 최적화를 수행함\\\n",
        "nesterov 매개변수를 True로 설정하면 네스테로프 모멘텀 최적화를 수행함\\\n",
        "**Adagrad**: Adagrad 옵티마이저 클래스\\\n",
        "learning_rate 매개변수로 학습률을 지정하며 기본값은 0.001\\\n",
        "Adagrad는 그레이디언트 제곱을 누적하여 학습률을 나눔\\\n",
        "initial_accumulator_value 매개변수에서 누적 초깃값을 지정할 수 있으며 기본값은 0.1\\\n",
        "**RMSprop**: RMSprop 옵티마이저 클래스\\\n",
        "learning_rate 매개변수로 학습률을 지정하며 기본값은 0.001\\\n",
        "Adagrad처럼 그레이디언트 제곱으로 학습률을 나누지만 최근의 그레이디언트를 사용하기 위해 지수 감소를 사용\\\n",
        "rho 매개변수에서 감소 비율을 지정하며 기본값은 0.9\\\n",
        "**Adam**: Adam 옵티마이저 클래스\\\n",
        "learnin_rate 매개변수로 학습률을 지정하며 기본값은 0.001\\\n",
        "모멘텀 최적화에 있는 그레이디언트의 지수 감소 평균을 조절하기 위해 beta_1 매개변수가 있으며 기본값은 0.9\\\n",
        "RMSprop에 있는 그레이디언트 제곱의 지수 감소 평균을 조절하기 위해 beta_2 매개변수가 있으며 기본값은 0.999\n",
        "# Tip\n",
        "1. 렐루(ReLU) 함수는 이미지 처리에서 좋은 성능을 낸다고 알려져 있다.\n",
        "2. 케라스 API눈 입력 데이터에 대한 전처리 과정을 될 수 있으면 모델에 포함한다.\n",
        "3. 분류 문제를 위한 신경망의 출력층에는 시그모이드 함수나 소프트맥스 함수를 활성화 함수로 사용한다. 회귀의 출력은 임의의 어떤 숫자이므로 활성화 함수를 적용할 필요가 없다. 은닉층의 활성화 함수는 비교적 자유롭다. 대표적으로 시그모이드 함수와 렐루 함수 등을 사용한다.\n",
        "4. flatten 층은 층이긴 하지만 심층 신경망의 깊이에는 카운트하지 않는다.\n",
        "5. model.summary()에서 Non-trainable params란 간혹 경사 하강법으로 훈련되지 않는 파라미터를 가진 층이 있다. 이런 층의 파라미터 개수가 여기에 나타난다."
      ],
      "metadata": {
        "id": "_9dELCJNZhDW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1KzeljXYa8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265746d2-e8ed-4d6c-991e-4fd8ca78a0b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "\"\"\"이미지 데이터 가져오기\"\"\"\n",
        "from tensorflow import keras\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "train_scaled = train_input / 255.0\n",
        "train_scaled = train_scaled.reshape(-1, 28*28)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"심층 신경망 만들기1.\"\"\"\n",
        "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
        "dense2 = keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "model = keras.Sequential([dense1, dense2])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXdSptdQnWp4",
        "outputId": "6b82faf0-362c-4568-d1ca-65b866920051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"심층 신경망 만들기2.\"\"\"\n",
        "model = keras.Sequential(\n",
        "    [keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n",
        "     keras.layers.Dense(10, activation='softmax', name='output')], name='Fashin MNIST Model'\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR5kOFtKneTf",
        "outputId": "cb5b20db-d710-415c-f917-e74cf5a2a61c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Fashin MNIST Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"심층 신경망 만들기3.\"\"\"\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY4PZuXAniyn",
        "outputId": "52211db1-63c0-4b18-8ec4-7f283848c888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 6s 3ms/step - loss: 0.5694 - accuracy: 0.8057\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4117 - accuracy: 0.8504\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3777 - accuracy: 0.8630\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3538 - accuracy: 0.8722\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3379 - accuracy: 0.8776\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a3a7840aad0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"flatten층과 렐루 함수\"\"\"\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "train_scaled = train_input / 255.0\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)\n",
        "\n",
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2QdgsYUnk2G",
        "outputId": "14c439c6-ffd9-4277-e60b-67cb62cda970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5317 - accuracy: 0.8110\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3923 - accuracy: 0.8589\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3535 - accuracy: 0.8720\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3307 - accuracy: 0.8823\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3162 - accuracy: 0.8864\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.8838\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33864837884902954, 0.8838333487510681]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"옵티마이저(경사 하강법 알고리즘)\"\"\"\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "#sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)\n",
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZa8SB5coNhz",
        "outputId": "e768a3f5-0933-4ea1-e96f-930d83f2f4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5205 - accuracy: 0.8194\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3918 - accuracy: 0.8600\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3559 - accuracy: 0.8705\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3264 - accuracy: 0.8817\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3076 - accuracy: 0.8879\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.8812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3325432240962982, 0.8811666369438171]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}